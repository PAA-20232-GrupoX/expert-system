“C rede convolutiva”, (“S imagens”; “S reconhecimento de padrões”), 0.85
“C rede convolutiva”, (“S imagens”; “S grande volume de dados”; “S alta variabilidade”), 0.75
“C modelo baseado em transformadores”, (“S imagens”; “S tarefa de segmentação”), 0.7
“C BERT para análise de sentimento”, (“S texto”; “S análise de sentimento”), 0.9
“C LSTM para sequências temporais”, (“S texto”; “S sequência temporal”), 0.8
“C transformador para tradução”, (“S texto”; “S tarefa de tradução”), 0.85
“C árvore de decisão”, (“S dados categóricos”; “S pequeno volume de dados”), 0.75
“C Random Forest”, (“S dados categóricos”; “S dados faltantes”), 0.8
“C SVM”, (“S dados contínuos”; “S pequena quantidade de features”), 0.7
“C regressão linear”, (“S dados lineares”; NOT “S grande complexidade”), 0.8
“C K-means”, (“S dados agrupáveis”; “S sem rótulos”), 0.75
“C rede neural profunda”, (“S grande volume de dados”; “S alta complexidade”), 0.9
“C algoritmo genético”, (“S otimização de parâmetros”; “S espaço de solução grande”), 0.6
“C redes Bayesianas”, (“S incerteza”; “S dados probabilísticos”), 0.7
“C algoritmo de agrupamento hierárquico”, (“S dados não rotulados”; “S necessidade de hierarquia”), 0.65
“C regressão logística”, (“S classificação binária”; “S dados lineares”), 0.8
“C Naive Bayes”, (“S classificação”; “S dados textuais”), 0.7
“C algoritmo A*”, (“S busca de caminho”; “S espaço de estado grande”), 0.8
“C algoritmo de Floresta Aleatória”, (“S classificação”; “S grande quantidade de dados”), 0.85
“C algoritmo de gradient boosting”, (“S rótulos claros”; “S grande volume”; “S desbalanceamento de classes”; “S alta dimensionalidade”; “S necessidade de classificação precisa”), 0.8
“C algoritmo de detecção de outliers LOF”, (“S outliers perceptíveis”; “S características espaciais”; “S alta dimensionalidade”; “S sensibilidade a outliers”), 0.7
“C redes neurais para processamento de linguagem natural”, (“S grande quantidade de texto”; “S necessidade de classificação textual”; “S variação linguística”; “S expressões de sentimentos”; “S demanda por tradução”), 0.9
“C algoritmo de busca tabu”, (“S parâmetros ajustáveis para otimização”; “S desafios de otimização combinatória”; “S busca por soluções ótimas locais”; “S complexidade computacional elevada”), 0.6
“C modelo de Markov oculto”, (“S dados sequenciais”; “S necessidade de modelagem de sequências”; “S padrões reconhecíveis”; “S probabilidades de eventos futuros”), 0.8
“C algoritmo de agrupamento Mean Shift”, (“S falta de rótulos pré-definidos”; “S necessidade de identificar clusters naturalmente”; “S variações de densidade nos dados”; “S interesse em exploração de dados”), 0.65
“C modelo de redes neurais para previsão de séries temporais”, (“S padrões temporais”; “S necessidade de previsão temporal”; “S tendências ao longo do tempo”; “S predições de curto e longo prazo”), 0.2
“C algoritmo de aprendizado semi-supervisionado”, (“S rótulos parciais”; “S economia na rotulação”; “S grandes volumes de dados”), 0.75
“C algoritmo de otimização de colônia de formigas”, (“S desafios de roteamento”; “S necessidade de otimizar caminhos”; “S comportamentos coletivos para modelar”; “S problemas logísticos complexos”), 0.7
“C algoritmo de aprendizado profundo para detecção de objetos”, (“S conteúdo imagético”; “S tarefas de detecção de objetos”; “S necessidade de análise de vídeo em tempo real”; “S padrões visuais distintos”), 0.85
“C regressão linear”, (“S relações lineares entre variáveis”; “S pequena quantidade de variáveis”; “S necessidade de previsão contínua”), 0.8
“C Naive Bayes para classificação”, (“S categorização simples de dados”; “S independência entre as variáveis”; “S pequeno volume de dados”), 0.7
“C algoritmo K-Nearest Neighbors”, (“S tarefas de classificação ou regressão simples”; “S dados rotulados”; “S pequenas distâncias entre pontos de dados”), 0.75
“C Support Vector Machine para classificação”, (“S necessidade de margem de separação clara”; “S dados de alta dimensionalidade”; “S classificação binária ou multiclasse”), 0.85
“C algoritmo de clustering K-means”, (“S necessidade de agrupamento de dados”; “S clara distinção entre clusters”; “S dados com tendências de agrupamento”), 0.9
“C rede neural artificial para classificação”, (“S tarefas complexas de classificação”; “S grande volume de dados”; “S alta variabilidade nos dados”), 0.8
“C algoritmo de Árvore de Decisão”, (“S tomada de decisão baseada em regras”; “S dados com estruturas hierárquicas”; “S classificação ou regressão simples”), 0.7
“C Random Forest para classificação ou regressão”, (“S conjuntos de dados grandes e complexos”; “S necessidade de redução de overfitting”; “S múltiplas variáveis de decisão”), 0.85
“C algoritmo de otimização por enxame de partículas”, (“S busca por soluções ótimas”; “S problemas de otimização contínua”; “S espaço de busca amplo”), 0.6
“C algoritmo de detecção de anomalias baseado em Autoencoder”, (“S dados com comportamentos anômalos”; “S grandes volumes de dados”; “S aprendizado não supervisionado”), 0.75
